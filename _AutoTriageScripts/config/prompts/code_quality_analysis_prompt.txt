Analyze this code quality issue:

Issue Information:
{issue}

File: {file_path}
Line: {line_number}
Type: {issue_type}
Severity: {severity}

{tools_documentation}

IMPORTANT: Your investigation should follow this pattern:
1. FIRST: Generate search terms from the issue (issue type, technology, file type, rule name) and call search_known_issues to find related human reviews
2. Review search results: If you find matches with high relevance scores (>5.0), call check_known_issue on the most relevant match to read the FULL details
3. If human review found: Read their complete reasoning and build upon their decision
4. If no relevant reviews: Read the relevant code using read_file or read_file_lines
5. Determine if the issue is valid based on the code you see
6. Call provide_analysis with your conclusion (typically after 1-2 tool calls)
7. ONLY use the tools listed in the documentation - do not invent new tools

Generating search terms:
- Include technology (e.g., "Docker", "Python", "JavaScript")
- Include issue type (e.g., "version tag", "code smell", "security hotspot")
- Include concepts (e.g., "false positive", "not applicable", "trivial")
- Use 3-5 specific terms that would appear in human reasoning

When human context exists:
- Acknowledge their decision and reasoning in your analysis
- Your investigation should verify or build upon their findings
- If you disagree with their assessment, explain why with specific evidence

When calling provide_analysis, you MUST assess the REAL WORLD severity:
- CRITICAL: Security vulnerability that could lead to data breach, RCE, or system compromise
- HIGH: Functional bug that breaks core features or causes data loss
- MEDIUM: Performance issues or bugs that affect non-critical functionality
- LOW: Code quality issues that should be addressed (unused code, potential bugs)
- TRIVIAL: Cosmetic issues, style preferences, formatting (alphabetical order, naming conventions, comments)

Be realistic about impact - issues like "packages not in alphabetical order" or "missing version tag" are TRIVIAL, not HIGH priority.

When providing your analysis, you MUST include:
- investigation_summary: Brief summary of what you investigated and how you reached your conclusion
- verification_steps: Specific, executable commands that the user can run
- limitations: What you couldn't check or potential gaps in your analysis

================================================================================
CRITICAL: ALWAYS USE FULL FILE PATHS (NON-NEGOTIABLE)
================================================================================

Extract the full path from 'component' field (remove project prefix like "AutoTriage:") and use it EVERYWHERE.

CORRECT: "Check container_security/vulnerable/Dockerfile line 2 for 'FROM ubuntu:latest'"
WRONG:   "Check Dockerfile line 2" or "Check the Dockerfile"

CORRECT: "grep -n 'apt-get install' container_security/vulnerable/Dockerfile"
WRONG:   "grep for packages in Dockerfile" or "Check the package list"

Every file mention, every command, every path â†’ FULL PATH. No exceptions.

FINAL CHECKLIST BEFORE CALLING provide_analysis:
[ ] Every file mentioned has its FULL path (e.g., container_security/vulnerable/Dockerfile)
[ ] Every command is copy-pasteable and includes full paths
[ ] No vague statements like "check the file" or "verify the code"
[ ] verification_steps are actual shell commands, not descriptions

Start by calling search_known_issues with relevant terms, then examine the code. You can include 'reasoning' in any tool call to organize your thoughts.

